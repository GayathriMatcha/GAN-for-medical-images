{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17613da6",
   "metadata": {},
   "source": [
    "# **StarGANv2:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbf1658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install munch\n",
    "# !pip install darkskylib\n",
    "# !pip install pyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e79f515",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "StarGAN v2\n",
    "Copyright (c) 2020-present NAVER Corp.\n",
    "This work is licensed under the Creative Commons Attribution-NonCommercial\n",
    "4.0 International License. To view a copy of this license, visit\n",
    "http://creativecommons.org/licenses/by-nc/4.0/ or send a letter to\n",
    "Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.\n",
    "\"\"\"\n",
    "\n",
    "import copy\n",
    "import math\n",
    "\n",
    "from munch import Munch\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# from core import *\n",
    "# from .core.wing import FAN\n",
    "# from core.wing import FAN\n",
    "# from pyping.core import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760b31f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install \n",
    "import ants\n",
    "import SimpleITK as sitk\n",
    "import sys\n",
    "import glob\n",
    "import os\n",
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sys.path.insert(0,'./basics/')\n",
    "import basics.slice_view as slice_view\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# torchsummary and torchvision\n",
    "from torchsummary import summary\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "# matplotlib stuff\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "\n",
    "# numpy and pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Common python packages\n",
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import h5py\n",
    "import pathlib\n",
    "import random\n",
    "import torch\n",
    "from skimage import feature\n",
    "# from utils import npComplexToTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04154e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlk(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out, actv=nn.LeakyReLU(0.2),\n",
    "                 normalize=False, downsample=False):\n",
    "        super().__init__()\n",
    "        self.actv = actv\n",
    "        self.normalize = normalize\n",
    "        self.downsample = downsample\n",
    "        self.learned_sc = dim_in != dim_out\n",
    "        self._build_weights(dim_in, dim_out)\n",
    "\n",
    "    def _build_weights(self, dim_in, dim_out):\n",
    "        self.conv1 = nn.Conv2d(dim_in, dim_in, 3, 1, 1)\n",
    "        self.conv2 = nn.Conv2d(dim_in, dim_out, 3, 1, 1)\n",
    "        if self.normalize:\n",
    "            self.norm1 = nn.InstanceNorm2d(dim_in, affine=True)\n",
    "            self.norm2 = nn.InstanceNorm2d(dim_in, affine=True)\n",
    "        if self.learned_sc:\n",
    "            self.conv1x1 = nn.Conv2d(dim_in, dim_out, 1, 1, 0, bias=False)\n",
    "\n",
    "    def _shortcut(self, x):\n",
    "        if self.learned_sc:\n",
    "            x = self.conv1x1(x)\n",
    "        if self.downsample:\n",
    "            x = F.avg_pool2d(x, 2)\n",
    "        return x\n",
    "\n",
    "    def _residual(self, x):\n",
    "        if self.normalize:\n",
    "            x = self.norm1(x)\n",
    "        x = self.actv(x)\n",
    "        x = self.conv1(x)\n",
    "        if self.downsample:\n",
    "            x = F.avg_pool2d(x, 2)\n",
    "        if self.normalize:\n",
    "            x = self.norm2(x)\n",
    "        x = self.actv(x)\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self._shortcut(x) + self._residual(x)\n",
    "        return x / math.sqrt(2)  # unit variance\n",
    "\n",
    "\n",
    "class AdaIN(nn.Module):\n",
    "    def __init__(self, style_dim, num_features):\n",
    "        super().__init__()\n",
    "        self.norm = nn.InstanceNorm2d(num_features, affine=False)\n",
    "        self.fc = nn.Linear(style_dim, num_features*2)\n",
    "\n",
    "    def forward(self, x, s):\n",
    "        h = self.fc(s)\n",
    "        h = h.view(h.size(0), h.size(1), 1, 1)\n",
    "        gamma, beta = torch.chunk(h, chunks=2, dim=1)\n",
    "        return (1 + gamma) * self.norm(x) + beta\n",
    "\n",
    "\n",
    "class AdainResBlk(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out, style_dim=64, w_hpf=0,\n",
    "                 actv=nn.LeakyReLU(0.2), upsample=False):\n",
    "        super().__init__()\n",
    "        self.w_hpf = w_hpf\n",
    "        self.actv = actv\n",
    "        self.upsample = upsample\n",
    "        self.learned_sc = dim_in != dim_out\n",
    "        self._build_weights(dim_in, dim_out, style_dim)\n",
    "\n",
    "    def _build_weights(self, dim_in, dim_out, style_dim=64):\n",
    "        self.conv1 = nn.Conv2d(dim_in, dim_out, 3, 1, 1)\n",
    "        self.conv2 = nn.Conv2d(dim_out, dim_out, 3, 1, 1)\n",
    "        self.norm1 = AdaIN(style_dim, dim_in)\n",
    "        self.norm2 = AdaIN(style_dim, dim_out)\n",
    "        if self.learned_sc:\n",
    "            self.conv1x1 = nn.Conv2d(dim_in, dim_out, 1, 1, 0, bias=False)\n",
    "\n",
    "    def _shortcut(self, x):\n",
    "        if self.upsample:\n",
    "            x = F.interpolate(x, scale_factor=2, mode='nearest')\n",
    "        if self.learned_sc:\n",
    "            x = self.conv1x1(x)\n",
    "        return x\n",
    "\n",
    "    def _residual(self, x, s):\n",
    "        x = self.norm1(x, s)\n",
    "        x = self.actv(x)\n",
    "        if self.upsample:\n",
    "            x = F.interpolate(x, scale_factor=2, mode='nearest')\n",
    "        x = self.conv1(x)\n",
    "        x = self.norm2(x, s)\n",
    "        x = self.actv(x)\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, s):\n",
    "        out = self._residual(x, s)\n",
    "        if self.w_hpf == 0:\n",
    "            out = (out + self._shortcut(x)) / math.sqrt(2)\n",
    "        return out\n",
    "\n",
    "\n",
    "class HighPass(nn.Module):\n",
    "    def __init__(self, w_hpf, device):\n",
    "        super(HighPass, self).__init__()\n",
    "        self.register_buffer('filter',\n",
    "                             torch.tensor([[-1, -1, -1],\n",
    "                                           [-1, 8., -1],\n",
    "                                           [-1, -1, -1]]) / w_hpf)\n",
    "\n",
    "    def forward(self, x):\n",
    "        filter = self.filter.unsqueeze(0).unsqueeze(1).repeat(x.size(1), 1, 1, 1)\n",
    "        return F.conv2d(x, filter, padding=1, groups=x.size(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949be1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(2**14)//256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33abccc3",
   "metadata": {},
   "source": [
    "## **Generator:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b42a125",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, img_size=240, style_dim=64, max_conv_dim=512, w_hpf=1):\n",
    "        super().__init__()\n",
    "        dim_in = 2**14 // img_size\n",
    "        self.img_size = img_size\n",
    "        self.from_rgb = nn.Conv2d(1, dim_in, 3, 1, 1)\n",
    "        self.encode = nn.ModuleList()\n",
    "        self.decode = nn.ModuleList()\n",
    "        self.to_rgb = nn.Sequential(\n",
    "            nn.InstanceNorm2d(dim_in, affine=True),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(dim_in, 1, 1, 1, 0))\n",
    "\n",
    "        # down/up-sampling blocks\n",
    "        repeat_num = int(np.log2(img_size)) - 4\n",
    "        if w_hpf > 0:\n",
    "            repeat_num += 1\n",
    "        for _ in range(repeat_num):\n",
    "            dim_out = min(dim_in*2, max_conv_dim)\n",
    "            self.encode.append(\n",
    "                ResBlk(dim_in, dim_out, normalize=True, downsample=True))\n",
    "            self.decode.insert(\n",
    "                0, AdainResBlk(dim_out, dim_in, style_dim,\n",
    "                               w_hpf=w_hpf, upsample=True))  # stack-like\n",
    "            dim_in = dim_out\n",
    "\n",
    "        # bottleneck blocks\n",
    "        for _ in range(2):\n",
    "            self.encode.append(\n",
    "                ResBlk(dim_out, dim_out, normalize=True))\n",
    "            self.decode.insert(\n",
    "                0, AdainResBlk(dim_out, dim_out, style_dim, w_hpf=w_hpf))\n",
    "\n",
    "        if w_hpf > 0:\n",
    "            device = torch.device(\n",
    "                'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            self.hpf = HighPass(w_hpf, device)\n",
    "\n",
    "    def forward(self, x, s, masks=None):\n",
    "        x = self.from_rgb(x)\n",
    "        cache = {}\n",
    "        for block in self.encode:\n",
    "            if (masks is not None) and (x.size(2) in [32, 64, 128]):\n",
    "                cache[x.size(2)] = x\n",
    "            x = block(x)\n",
    "        for block in self.decode:\n",
    "            x = block(x, s)\n",
    "            if (masks is not None) and (x.size(2) in [32, 64, 128]):\n",
    "                mask = masks[0] if x.size(2) in [32] else masks[1]\n",
    "                mask = F.interpolate(mask, size=x.size(2), mode='bilinear')\n",
    "                x = x + self.hpf(mask * cache[x.size(2)])\n",
    "        return self.to_rgb(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dd0b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((1,1,240,240)).cuda()\n",
    "c = torch.zeros((1,64)).cuda()\n",
    "# torch.long\n",
    "# k = torch.LongTensor(c).cuda()\n",
    "# k=c.long()\n",
    "# print(k.shape)\n",
    "# c[0,0] = 1.0\n",
    "gen = Generator().cuda()\n",
    "d = gen(x, c)\n",
    "print(x.shape)\n",
    "print(c.shape)\n",
    "print(d.shape)\n",
    "# print(k.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbb3278",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(Generator().cuda(), [(1,240,240),(64,4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56518ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47095d3b",
   "metadata": {},
   "source": [
    "## **Mapping Network:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e2d14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.LongTensor(range(3)).cuda()\n",
    "idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba998798",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MappingNetwork(nn.Module):\n",
    "    def __init__(self, latent_dim=16, style_dim=64, num_domains=2):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        layers += [nn.Linear(latent_dim, 512)]\n",
    "        layers += [nn.ReLU()]\n",
    "        for _ in range(3):\n",
    "            layers += [nn.Linear(512, 512)]\n",
    "            layers += [nn.ReLU()]\n",
    "        self.shared = nn.Sequential(*layers)\n",
    "\n",
    "        self.unshared = nn.ModuleList()\n",
    "        for _ in range(num_domains):\n",
    "            self.unshared += [nn.Sequential(nn.Linear(512, 512),\n",
    "                                            nn.ReLU(),\n",
    "                                            nn.Linear(512, 512),\n",
    "                                            nn.ReLU(),\n",
    "                                            nn.Linear(512, 512),\n",
    "                                            nn.ReLU(),\n",
    "                                            nn.Linear(512, style_dim))]\n",
    "\n",
    "    def forward(self, z, y):\n",
    "        h = self.shared(z)\n",
    "        out = []\n",
    "        for layer in self.unshared:\n",
    "            out += [layer(h)]\n",
    "        out = torch.stack(out, dim=1)  # (batch, num_domains, style_dim)\n",
    "#         print(out)\n",
    "#         print(out.shape)\n",
    "        idx = torch.LongTensor(range(y.size(0))).to(y.device)\n",
    "#         print(idx)\n",
    "        s = out[idx, y]  # (batch, style_dim)\n",
    "#         print(s)\n",
    "        \n",
    "        return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54738525",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((4,2,5)).cuda()\n",
    "idx = torch.LongTensor(range(4)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79d9c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.zeros((1,4)).cuda()\n",
    "y[0][2]=1\n",
    "# print(y.shape)\n",
    "y=y.long()\n",
    "\n",
    "\n",
    "s= x[idx,y]\n",
    "print(idx.dtype)\n",
    "print(y.shape)\n",
    "print(x.shape)\n",
    "print(s.shape)\n",
    "# print(x)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491c8dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((1,16)).cuda()\n",
    "c = torch.zeros((1,4)).cuda()\n",
    "# torch.long\n",
    "# k = torch.LongTensor(c).cuda()\n",
    "k=c.long()\n",
    "print(k.shape)\n",
    "# c[0,0] = 1.0\n",
    "gen = MappingNetwork().cuda()\n",
    "d = gen(x, k)\n",
    "print(d.shape)\n",
    "print(k.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68755aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary(MappingNetwork().cuda(), [(16),(2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8d2d2f",
   "metadata": {},
   "source": [
    "## **Style Encoder:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630fc0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleEncoder(nn.Module):\n",
    "    def __init__(self, img_size=256, style_dim=64, num_domains=2, max_conv_dim=512):\n",
    "        super().__init__()\n",
    "        dim_in = 2**14 // img_size\n",
    "        blocks = []\n",
    "        blocks += [nn.Conv2d(1, dim_in, 3, 1, 1)]\n",
    "\n",
    "        repeat_num = int(np.log2(img_size)) - 2\n",
    "        for _ in range(repeat_num):\n",
    "            dim_out = min(dim_in*2, max_conv_dim)\n",
    "            blocks += [ResBlk(dim_in, dim_out, downsample=True)]\n",
    "            dim_in = dim_out\n",
    "\n",
    "        blocks += [nn.LeakyReLU(0.2)]\n",
    "        blocks += [nn.Conv2d(dim_out, dim_out, 4, 1, 0)]\n",
    "        blocks += [nn.LeakyReLU(0.2)]\n",
    "        self.shared = nn.Sequential(*blocks)\n",
    "\n",
    "        self.unshared = nn.ModuleList()\n",
    "        for _ in range(num_domains):\n",
    "            self.unshared += [nn.Linear(dim_out, style_dim)]\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        h = self.shared(x)\n",
    "        h = h.view(h.size(0), -1)\n",
    "        out = []\n",
    "        for layer in self.unshared:\n",
    "            out += [layer(h)]\n",
    "        out = torch.stack(out, dim=1)  # (batch, num_domains, style_dim)\n",
    "        idx = torch.LongTensor(range(y.size(0))).to(y.device)\n",
    "        s = out[idx, y]  # (batch, style_dim)\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec326478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2**14 // 256\n",
    "# int(np.log2(240)) - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1493d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((1,1,256,256)).cuda()\n",
    "c = torch.zeros((1,4)).cuda()\n",
    "# torch.long\n",
    "# k = torch.LongTensor(c).cuda()\n",
    "k=c.long()\n",
    "print(k.shape)\n",
    "\n",
    "gen3 = StyleEncoder().cuda()\n",
    "d = gen3(x, k)\n",
    "print(d.shape)\n",
    "print(k.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f368f0",
   "metadata": {},
   "source": [
    "## **Discriminator:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad81b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_size=256, num_domains=2, max_conv_dim=512):\n",
    "        super().__init__()\n",
    "        dim_in = 2**14 // img_size\n",
    "        blocks = []\n",
    "        blocks += [nn.Conv2d(1, dim_in, 3, 1, 1)]\n",
    "\n",
    "        repeat_num = int(np.log2(img_size)) - 2\n",
    "        for _ in range(repeat_num):\n",
    "            dim_out = min(dim_in*2, max_conv_dim)\n",
    "            blocks += [ResBlk(dim_in, dim_out, downsample=True)]\n",
    "            dim_in = dim_out\n",
    "\n",
    "        blocks += [nn.LeakyReLU(0.2)]\n",
    "        blocks += [nn.Conv2d(dim_out, dim_out, 4, 1, 0)]\n",
    "        blocks += [nn.LeakyReLU(0.2)]\n",
    "        blocks += [nn.Conv2d(dim_out, num_domains, 1, 1, 0)]\n",
    "        self.main = nn.Sequential(*blocks)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        out = self.main(x)\n",
    "        out = out.view(out.size(0), -1)  # (batch, num_domains)\n",
    "        idx = torch.LongTensor(range(y.size(0))).to(y.device)\n",
    "        out = out[idx, y]  # (batch)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e97b38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((1,1,256,256)).cuda()\n",
    "c = torch.zeros((1,1,4)).cuda()\n",
    "# torch.long\n",
    "# k = torch.LongTensor(c).cuda()\n",
    "k=c.long()\n",
    "print(k.shape)\n",
    "# c[0,0] = 1.0\n",
    "gen3 = Discriminator().cuda()\n",
    "d = gen3(x, k)\n",
    "print(d.shape)\n",
    "print(k.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5f8f19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
