{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d66111c",
   "metadata": {},
   "outputs": [],
   "source": [
    "root='/media/Data/MRI/datasets/'\n",
    "filename1 = '/media/Data/MRI/datasets/mrbrain_t1/cartesian/train/acc_4x/'\n",
    "filename2 = '/media/Data/MRI/datasets/mrbrain_ir/cartesian/train/acc_4x/'\n",
    "filename3 = '/media/Data/MRI/datasets/mrbrain_flair/cartesian/train/acc_4x/'\n",
    "\n",
    "class mrDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, root, mode=\"train\"):\n",
    "\n",
    "#         files = sorted(os.listdir(root))\n",
    "#         patient_id = list(set([i.split()[0] for i in files]))\n",
    "        patient_id =list(range(0, 5))\n",
    "\n",
    "        imgs_t1 = []\n",
    "        imgs_ir = []\n",
    "        imgs_flr = []\n",
    "\n",
    "        if mode == \"train\":\n",
    "            for i in range(len(patient_id)):\n",
    "                if (os.path.isfile(os.path.join(filename1, str(i) + \".h5\"))):\n",
    "                    imgs_t1.append(h5py.File(os.path.join(filename1, str(i) + \".h5\"), \"r\"))\n",
    "                if (os.path.isfile(os.path.join(filename2, str(i) + \".h5\"))):\n",
    "                    imgs_ir.append(h5py.File(os.path.join(filename2, str(i) + \".h5\"), \"r\"))\n",
    "                if (os.path.isfile(os.path.join(filename3, str(i) + \".h5\"))):\n",
    "                    imgs_flr.append(h5py.File(os.path.join(filename3, str(i) + \".h5\"), \"r\"))\n",
    "                    \n",
    "\n",
    "        elif mode == \"test\":\n",
    "            for i in range(2):\n",
    "                if (os.path.isfile(os.path.join(filename1, str(i) + \".h5\"))):\n",
    "                    imgs_t1.append(h5py.File(os.path.join(filename1, str(i) + \".h5\"), \"r\"))\n",
    "                if (os.path.isfile(os.path.join(filename2, str(i) + \".h5\"))):\n",
    "                    imgs_ir.append(h5py.File(os.path.join(filename2, str(i) + \".h5\"), \"r\"))\n",
    "                if (os.path.isfile(os.path.join(filename3, str(i) + \".h5\"))):\n",
    "                    imgs_flr.append(h5py.File(os.path.join(filename3, str(i) + \".h5\"), \"r\"))\n",
    "\n",
    "        self.imgs_t1 = imgs_t1\n",
    "        self.imgs_ir = imgs_ir\n",
    "        self.imgs_flr = imgs_flr\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "#         t1_path, ADC_path, PD_path, DCE_path = self.imgs[index]\n",
    "        \n",
    "        t1=self.imgs_t1[index]\n",
    "        a = list(t1.keys())[3]\n",
    "        data_t1 = np.asarray(t1[a])\n",
    "        \n",
    "        ir=self.imgs_ir[index]\n",
    "        b = list(ir.keys())[2]\n",
    "        data_ir = np.asarray(ir[b])\n",
    "        \n",
    "        flr=self.imgs_flr[index]\n",
    "        c = list(flr.keys())[2]\n",
    "        data_flr = np.asarray(flr[c])\n",
    "\n",
    "\n",
    "        return {\"T1\": data_t1, \"IR\": data_ir, \"FLR\":data_flr}\n",
    "#         return {\"data\": data,\"labels\": labels}\n",
    "#         return{}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f758ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True if torch.cuda.is_available() else False\n",
    "print(f\"Using cuda device: {cuda}\")  # check if GPU is used\n",
    "\n",
    "# Tensor type (put everything on GPU if possible)\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faf59b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(mrDataset(root,mode='train'),batch_size=1,shuffle=False)\n",
    "\n",
    "\n",
    "# Parameters for Adam optimizer\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "beta2 = 0.999\n",
    "\n",
    "# Create dataloaders\n",
    "# batch_size = 40\n",
    "train_loader =torch.utils.data.DataLoader(mrDataset(root,mode='train'),batch_size=1,shuffle=False)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(mrDataset(root,mode='test'),batch_size=1,shuffle=False)\n",
    "\n",
    "# Number of epochs\n",
    "num_epoch = 20\n",
    "\n",
    "# Train the generator\n",
    "# generator = train_generator(train_loader, test_loader, num_epoch=num_epoch,\n",
    "#                              lr=lr, beta1=beta1, beta2=beta2)\n",
    "\n",
    "for i, batch in enumerate(train_loader):\n",
    "\n",
    "    # Inputs T1-w and T2-w\n",
    "    real_t1 = batch[\"T1\"].type(Tensor)\n",
    "    print(real_t1.shape)\n",
    "    real_ir = batch[\"IR\"].type(Tensor)\n",
    "    print(real_ir.shape)\n",
    "    real_flr = batch[\"FLR\"].type(Tensor)\n",
    "    print(real_flr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0068b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef397b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b074cf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "root='/media/Data/MRI/datasets/'\n",
    "\n",
    "class SliceData(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset that provides access to MR image slices.\n",
    "    \"\"\"\n",
    "    filename1 = '/media/Data/MRI/datasets/mrbrain_t1/cartesian/train/acc_4x/'\n",
    "    filename2 = '/media/Data/MRI/datasets/mrbrain_ir/cartesian/train/acc_4x/'\n",
    "    filename3 = '/media/Data/MRI/datasets/mrbrain_flair/cartesian/train/acc_4x/'\n",
    "\n",
    "    #def __init__(self, root, acc_factor,dataset_type,mask_path): # acc_factor can be passed here and saved as self variable\n",
    "    def __init__(self, root): # acc_factor can be passed here and saved as self variable\n",
    "        # List the h5 files in root \n",
    "        fn1 = list(pathlib.Path(filename1).iterdir())\n",
    "        fn2 = list(pathlib.Path(filename2).iterdir())\n",
    "        fn3 = list(pathlib.Path(filename3).iterdir())\n",
    "        self.examples_t1 = []\n",
    "        self.examples_ir = []\n",
    "        self.examples_flr = []\n",
    "\n",
    "        for fname in sorted(fn1):\n",
    "            with h5py.File(fname,'r') as hf:\n",
    "                fsvol = hf['volfs']\n",
    "                num_slices = fsvol.shape[2]\n",
    "                self.examples_t1 += [(fname, slice) for slice in range(num_slices)]\n",
    "        for fname in sorted(fn2):\n",
    "            with h5py.File(fname,'r') as hf:\n",
    "                fsvol = hf['volfs']\n",
    "                num_slices = fsvol.shape[2]\n",
    "                self.examples_ir += [(fname, slice) for slice in range(num_slices)]\n",
    "        for fname in sorted(fn3):\n",
    "            with h5py.File(fname,'r') as hf:\n",
    "                fsvol = hf['volfs']\n",
    "                num_slices = fsvol.shape[2]\n",
    "                self.examples_flr += [(fname, slice) for slice in range(num_slices)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples_t1)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # Index the fname and slice using the list created in __init__\n",
    "        \n",
    "        fname1, slice = self.examples_t1[i] \n",
    "        fname2, slice = self.examples_ir[i]\n",
    "        fname3, slice = self.examples_flr[i]\n",
    "        # Print statements \n",
    "        #print (fname,slice)\n",
    "    \n",
    "        with h5py.File(fname1, 'r') as data:    \n",
    "            t1 = data['volfs'][:,:,slice].astype(np.float64)\n",
    "        with h5py.File(fname2, 'r') as data:    \n",
    "            ir = data['volfs'][:,:,slice].astype(np.float64)\n",
    "        with h5py.File(fname3, 'r') as data:    \n",
    "            flr = data['volfs'][:,:,slice].astype(np.float64)\n",
    "\n",
    "\n",
    "        return torch.from_numpy(t1), torch.from_numpy(ir), torch.from_numpy(flr)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777aff5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(SliceData(root),batch_size=1,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7ade1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,batch in enumerate(dataloader):\n",
    "    real_t1=batch[0]\n",
    "    real_ir=batch[1]\n",
    "    real_flr=batch[2]\n",
    "    print(real_t1.shape)\n",
    "    print(real_ir.shape)\n",
    "    print(real_flr.shape)\n",
    "    break\n",
    "real_t1.shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09d53be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import os \n",
    "from fnmatch import fnmatch\n",
    "from tqdm import tqdm \n",
    "import numpy as np\n",
    "import h5py \n",
    "# import sys\n",
    "# Converts the kribi nii to h5 files. \n",
    "# Data is not normalized in this case.\n",
    "\n",
    "root =  sys.argv[1]#'/media/Data/MRI/datasets/dataset_creation/IXI/niifiles/pd_nii/HH/train/'\n",
    "out_path= sys.argv[2]#'/media/Data/MRI/datasets/dataset_creation/IXI/niifiles/pd_nii/HH/train/h5/'\n",
    "pattern = '*.nii.gz'\n",
    "\n",
    "volume_list = []\n",
    "\n",
    "for path, subdirs, files in os.walk(root):\n",
    "    for name in files:\n",
    "        if fnmatch(name, pattern):\n",
    "            volume_path = os.path.join(path, name)\n",
    "            volume_list.append(volume_path)\n",
    "\n",
    "print (\"No of volumes:{}\".format(len(volume_list)))\n",
    "\n",
    "\n",
    "for iter,vol_path in enumerate(tqdm(volume_list)):\n",
    "\n",
    "    inp_vol_path = vol_path \n",
    "    imgvol  = nib.load(inp_vol_path)\n",
    "    imgvol_data_flipped = imgvol.get_fdata()\n",
    "    \n",
    "#    start_slice = 20 # used initially\n",
    "#    end_slice   = imgvol_data.shape[0] - 20\n",
    "    imgvol_data = np.flip(imgvol_data_flipped,axis=1)\n",
    "\n",
    "    start_slice = 30\n",
    "    end_slice   = imgvol_data.shape[0] - 70\n",
    "\n",
    "    imgvol = imgvol_data[8:248,16:256,start_slice:end_slice]\n",
    "    #imgvol = imgvol_data[start_slice:end_slice,:,:]\n",
    "    #imgvol = np.transpose(imgvol,(1,2,0))\n",
    "\n",
    "    save_path = os.path.join(out_path,'{}.h5'.format(iter))\n",
    "    \n",
    "    with h5py.File(save_path,'w') as f:\n",
    "        f.create_dataset('inpVol',data=imgvol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fd037f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
